// This file is @generated by prost-build.
/// Represents preferences for sending email notifications for transfer run
/// events.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct EmailPreferences {
    /// If true, email notifications will be sent on transfer run failures.
    #[prost(bool, tag = "1")]
    pub enable_failure_email: bool,
}
/// Options customizing the data transfer schedule.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct ScheduleOptions {
    /// If true, automatic scheduling of data transfer runs for this configuration
    /// will be disabled. The runs can be started on ad-hoc basis using
    /// StartManualTransferRuns API. When automatic scheduling is disabled, the
    /// TransferConfig.schedule field will be ignored.
    #[prost(bool, tag = "3")]
    pub disable_auto_scheduling: bool,
    /// Specifies time to start scheduling transfer runs. The first run will be
    /// scheduled at or after the start time according to a recurrence pattern
    /// defined in the schedule string. The start time can be changed at any
    /// moment. The time when a data transfer can be triggered manually is not
    /// limited by this option.
    #[prost(message, optional, tag = "1")]
    pub start_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Defines time to stop scheduling transfer runs. A transfer run cannot be
    /// scheduled at or after the end time. The end time can be changed at any
    /// moment. The time when a data transfer can be triggered manually is not
    /// limited by this option.
    #[prost(message, optional, tag = "2")]
    pub end_time: ::core::option::Option<::prost_types::Timestamp>,
}
/// V2 options customizing different types of data transfer schedule.
/// This field supports existing time-based and manual transfer schedule. Also
/// supports Event-Driven transfer schedule. ScheduleOptionsV2 cannot be used
/// together with ScheduleOptions/Schedule.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ScheduleOptionsV2 {
    /// Data transfer schedules.
    #[prost(oneof = "schedule_options_v2::Schedule", tags = "1, 2, 3")]
    pub schedule: ::core::option::Option<schedule_options_v2::Schedule>,
}
/// Nested message and enum types in `ScheduleOptionsV2`.
pub mod schedule_options_v2 {
    /// Data transfer schedules.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Schedule {
        /// Time based transfer schedule options. This is the default schedule
        /// option.
        #[prost(message, tag = "1")]
        TimeBasedSchedule(super::TimeBasedSchedule),
        /// Manual transfer schedule. If set, the transfer run will not be
        /// auto-scheduled by the system, unless the client invokes
        /// StartManualTransferRuns.  This is equivalent to
        /// disable_auto_scheduling = true.
        #[prost(message, tag = "2")]
        ManualSchedule(super::ManualSchedule),
        /// Event driven transfer schedule options. If set, the transfer will be
        /// scheduled upon events arrial.
        #[prost(message, tag = "3")]
        EventDrivenSchedule(super::EventDrivenSchedule),
    }
}
/// Options customizing the time based transfer schedule.
/// Options are migrated from the original ScheduleOptions message.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct TimeBasedSchedule {
    /// Data transfer schedule.
    /// If the data source does not support a custom schedule, this should be
    /// empty. If it is empty, the default value for the data source will be used.
    /// The specified times are in UTC.
    /// Examples of valid format:
    /// `1st,3rd monday of month 15:30`,
    /// `every wed,fri of jan,jun 13:15`, and
    /// `first sunday of quarter 00:00`.
    /// See more explanation about the format here:
    /// <https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format>
    ///
    /// NOTE: The minimum interval time between recurring transfers depends on the
    /// data source; refer to the documentation for your data source.
    #[prost(string, tag = "1")]
    pub schedule: ::prost::alloc::string::String,
    /// Specifies time to start scheduling transfer runs. The first run will be
    /// scheduled at or after the start time according to a recurrence pattern
    /// defined in the schedule string. The start time can be changed at any
    /// moment.
    #[prost(message, optional, tag = "2")]
    pub start_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Defines time to stop scheduling transfer runs. A transfer run cannot be
    /// scheduled at or after the end time. The end time can be changed at any
    /// moment.
    #[prost(message, optional, tag = "3")]
    pub end_time: ::core::option::Option<::prost_types::Timestamp>,
}
/// Options customizing manual transfers schedule.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct ManualSchedule {}
/// Options customizing EventDriven transfers schedule.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct EventDrivenSchedule {
    /// Pub/Sub subscription name used to receive events.
    /// Only Google Cloud Storage data source support this option.
    /// Format: projects/{project}/subscriptions/{subscription}
    #[prost(string, tag = "1")]
    pub pubsub_subscription: ::prost::alloc::string::String,
}
/// Information about a user.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct UserInfo {
    /// E-mail address of the user.
    #[prost(string, optional, tag = "1")]
    pub email: ::core::option::Option<::prost::alloc::string::String>,
}
/// Represents a data transfer configuration. A transfer configuration
/// contains all metadata needed to perform a data transfer. For example,
/// `destination_dataset_id` specifies where data should be stored.
/// When a new transfer configuration is created, the specified
/// `destination_dataset_id` is created when needed and shared with the
/// appropriate data source service account.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct TransferConfig {
    /// Identifier. The resource name of the transfer config.
    /// Transfer config names have the form either
    /// `projects/{project_id}/locations/{region}/transferConfigs/{config_id}` or
    /// `projects/{project_id}/transferConfigs/{config_id}`,
    /// where `config_id` is usually a UUID, even though it is not
    /// guaranteed or required. The name is ignored when creating a transfer
    /// config.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// User specified display name for the data transfer.
    #[prost(string, tag = "3")]
    pub display_name: ::prost::alloc::string::String,
    /// Data source ID. This cannot be changed once data transfer is created. The
    /// full list of available data source IDs can be returned through an API call:
    /// <https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list>
    #[prost(string, tag = "5")]
    pub data_source_id: ::prost::alloc::string::String,
    /// Parameters specific to each data source. For more information see the
    /// bq tab in the 'Setting up a data transfer' section for each data source.
    /// For example the parameters for Cloud Storage transfers are listed here:
    /// <https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq>
    #[prost(message, optional, tag = "9")]
    pub params: ::core::option::Option<::prost_types::Struct>,
    /// Data transfer schedule.
    /// If the data source does not support a custom schedule, this should be
    /// empty. If it is empty, the default value for the data source will be used.
    /// The specified times are in UTC.
    /// Examples of valid format:
    /// `1st,3rd monday of month 15:30`,
    /// `every wed,fri of jan,jun 13:15`, and
    /// `first sunday of quarter 00:00`.
    /// See more explanation about the format here:
    /// <https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format>
    ///
    /// NOTE: The minimum interval time between recurring transfers depends on the
    /// data source; refer to the documentation for your data source.
    #[prost(string, tag = "7")]
    pub schedule: ::prost::alloc::string::String,
    /// Options customizing the data transfer schedule.
    #[prost(message, optional, tag = "24")]
    pub schedule_options: ::core::option::Option<ScheduleOptions>,
    /// Options customizing different types of data transfer schedule.
    /// This field replaces "schedule" and "schedule_options" fields.
    /// ScheduleOptionsV2 cannot be used together with ScheduleOptions/Schedule.
    #[prost(message, optional, tag = "31")]
    pub schedule_options_v2: ::core::option::Option<ScheduleOptionsV2>,
    /// The number of days to look back to automatically refresh the data.
    /// For example, if `data_refresh_window_days = 10`, then every day
    /// BigQuery reingests data for \[today-10, today-1\], rather than ingesting data
    /// for just \[today-1\].
    /// Only valid if the data source supports the feature. Set the value to 0
    /// to use the default value.
    #[prost(int32, tag = "12")]
    pub data_refresh_window_days: i32,
    /// Is this config disabled. When set to true, no runs will be scheduled for
    /// this transfer config.
    #[prost(bool, tag = "13")]
    pub disabled: bool,
    /// Output only. Data transfer modification time. Ignored by server on input.
    #[prost(message, optional, tag = "4")]
    pub update_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Output only. Next time when data transfer will run.
    #[prost(message, optional, tag = "8")]
    pub next_run_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Output only. State of the most recently updated transfer run.
    #[prost(enumeration = "TransferState", tag = "10")]
    pub state: i32,
    /// Deprecated. Unique ID of the user on whose behalf transfer is done.
    #[prost(int64, tag = "11")]
    pub user_id: i64,
    /// Output only. Region in which BigQuery dataset is located.
    #[prost(string, tag = "14")]
    pub dataset_region: ::prost::alloc::string::String,
    /// Pub/Sub topic where notifications will be sent after transfer runs
    /// associated with this transfer config finish.
    ///
    /// The format for specifying a pubsub topic is:
    /// `projects/{project_id}/topics/{topic_id}`
    #[prost(string, tag = "15")]
    pub notification_pubsub_topic: ::prost::alloc::string::String,
    /// Email notifications will be sent according to these preferences
    /// to the email address of the user who owns this transfer config.
    #[prost(message, optional, tag = "18")]
    pub email_preferences: ::core::option::Option<EmailPreferences>,
    /// Output only. Information about the user whose credentials are used to
    /// transfer data. Populated only for `transferConfigs.get` requests. In case
    /// the user information is not available, this field will not be populated.
    #[prost(message, optional, tag = "27")]
    pub owner_info: ::core::option::Option<UserInfo>,
    /// The encryption configuration part. Currently, it is only used for the
    /// optional KMS key name. The BigQuery service account of your project must be
    /// granted permissions to use the key. Read methods will return the key name
    /// applied in effect. Write methods will apply the key if it is present, or
    /// otherwise try to apply project default keys if it is absent.
    #[prost(message, optional, tag = "28")]
    pub encryption_configuration: ::core::option::Option<EncryptionConfiguration>,
    /// Output only. Error code with detailed information about reason of the
    /// latest config failure.
    #[prost(message, optional, tag = "32")]
    pub error: ::core::option::Option<super::super::super::super::rpc::Status>,
    /// The desination of the transfer config.
    #[prost(oneof = "transfer_config::Destination", tags = "2")]
    pub destination: ::core::option::Option<transfer_config::Destination>,
}
/// Nested message and enum types in `TransferConfig`.
pub mod transfer_config {
    /// The desination of the transfer config.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Destination {
        /// The BigQuery target dataset id.
        #[prost(string, tag = "2")]
        DestinationDatasetId(::prost::alloc::string::String),
    }
}
/// Represents the encryption configuration for a transfer.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct EncryptionConfiguration {
    /// The name of the KMS key used for encrypting BigQuery data.
    #[prost(message, optional, tag = "1")]
    pub kms_key_name: ::core::option::Option<::prost::alloc::string::String>,
}
/// Represents a data transfer run.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct TransferRun {
    /// Identifier. The resource name of the transfer run.
    /// Transfer run names have the form
    /// `projects/{project_id}/locations/{location}/transferConfigs/{config_id}/runs/{run_id}`.
    /// The name is ignored when creating a transfer run.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Minimum time after which a transfer run can be started.
    #[prost(message, optional, tag = "3")]
    pub schedule_time: ::core::option::Option<::prost_types::Timestamp>,
    /// For batch transfer runs, specifies the date and time of the data should be
    /// ingested.
    #[prost(message, optional, tag = "10")]
    pub run_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Status of the transfer run.
    #[prost(message, optional, tag = "21")]
    pub error_status: ::core::option::Option<super::super::super::super::rpc::Status>,
    /// Output only. Time when transfer run was started.
    /// Parameter ignored by server for input requests.
    #[prost(message, optional, tag = "4")]
    pub start_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Output only. Time when transfer run ended.
    /// Parameter ignored by server for input requests.
    #[prost(message, optional, tag = "5")]
    pub end_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Output only. Last time the data transfer run state was updated.
    #[prost(message, optional, tag = "6")]
    pub update_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Output only. Parameters specific to each data source. For more information
    /// see the bq tab in the 'Setting up a data transfer' section for each data
    /// source. For example the parameters for Cloud Storage transfers are listed
    /// here:
    /// <https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq>
    #[prost(message, optional, tag = "9")]
    pub params: ::core::option::Option<::prost_types::Struct>,
    /// Output only. Data source id.
    #[prost(string, tag = "7")]
    pub data_source_id: ::prost::alloc::string::String,
    /// Data transfer run state. Ignored for input requests.
    #[prost(enumeration = "TransferState", tag = "8")]
    pub state: i32,
    /// Deprecated. Unique ID of the user on whose behalf transfer is done.
    #[prost(int64, tag = "11")]
    pub user_id: i64,
    /// Output only. Describes the schedule of this transfer run if it was
    /// created as part of a regular schedule. For batch transfer runs that are
    /// scheduled manually, this is empty.
    /// NOTE: the system might choose to delay the schedule depending on the
    /// current load, so `schedule_time` doesn't always match this.
    #[prost(string, tag = "12")]
    pub schedule: ::prost::alloc::string::String,
    /// Output only. Pub/Sub topic where a notification will be sent after this
    /// transfer run finishes.
    ///
    /// The format for specifying a pubsub topic is:
    /// `projects/{project_id}/topics/{topic_id}`
    #[prost(string, tag = "23")]
    pub notification_pubsub_topic: ::prost::alloc::string::String,
    /// Output only. Email notifications will be sent according to these
    /// preferences to the email address of the user who owns the transfer config
    /// this run was derived from.
    #[prost(message, optional, tag = "25")]
    pub email_preferences: ::core::option::Option<EmailPreferences>,
    /// Data transfer destination.
    #[prost(oneof = "transfer_run::Destination", tags = "2")]
    pub destination: ::core::option::Option<transfer_run::Destination>,
}
/// Nested message and enum types in `TransferRun`.
pub mod transfer_run {
    /// Data transfer destination.
    #[derive(Clone, PartialEq, ::prost::Oneof)]
    pub enum Destination {
        /// Output only. The BigQuery target dataset id.
        #[prost(string, tag = "2")]
        DestinationDatasetId(::prost::alloc::string::String),
    }
}
/// Represents a user facing message for a particular data transfer run.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct TransferMessage {
    /// Time when message was logged.
    #[prost(message, optional, tag = "1")]
    pub message_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Message severity.
    #[prost(enumeration = "transfer_message::MessageSeverity", tag = "2")]
    pub severity: i32,
    /// Message text.
    #[prost(string, tag = "3")]
    pub message_text: ::prost::alloc::string::String,
}
/// Nested message and enum types in `TransferMessage`.
pub mod transfer_message {
    /// Represents data transfer user facing message severity.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum MessageSeverity {
        /// No severity specified.
        Unspecified = 0,
        /// Informational message.
        Info = 1,
        /// Warning message.
        Warning = 2,
        /// Error message.
        Error = 3,
    }
    impl MessageSeverity {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "MESSAGE_SEVERITY_UNSPECIFIED",
                Self::Info => "INFO",
                Self::Warning => "WARNING",
                Self::Error => "ERROR",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "MESSAGE_SEVERITY_UNSPECIFIED" => Some(Self::Unspecified),
                "INFO" => Some(Self::Info),
                "WARNING" => Some(Self::Warning),
                "ERROR" => Some(Self::Error),
                _ => None,
            }
        }
    }
}
/// DEPRECATED. Represents data transfer type.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum TransferType {
    /// Invalid or Unknown transfer type placeholder.
    Unspecified = 0,
    /// Batch data transfer.
    Batch = 1,
    /// Streaming data transfer. Streaming data source currently doesn't
    /// support multiple transfer configs per project.
    Streaming = 2,
}
impl TransferType {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "TRANSFER_TYPE_UNSPECIFIED",
            Self::Batch => "BATCH",
            Self::Streaming => "STREAMING",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TRANSFER_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
            "BATCH" => Some(Self::Batch),
            "STREAMING" => Some(Self::Streaming),
            _ => None,
        }
    }
}
/// Represents data transfer run state.
#[derive(Clone, Copy, Debug, PartialEq, Eq, Hash, PartialOrd, Ord, ::prost::Enumeration)]
#[repr(i32)]
pub enum TransferState {
    /// State placeholder (0).
    Unspecified = 0,
    /// Data transfer is scheduled and is waiting to be picked up by
    /// data transfer backend (2).
    Pending = 2,
    /// Data transfer is in progress (3).
    Running = 3,
    /// Data transfer completed successfully (4).
    Succeeded = 4,
    /// Data transfer failed (5).
    Failed = 5,
    /// Data transfer is cancelled (6).
    Cancelled = 6,
}
impl TransferState {
    /// String value of the enum field names used in the ProtoBuf definition.
    ///
    /// The values are not transformed in any way and thus are considered stable
    /// (if the ProtoBuf definition does not change) and safe for programmatic use.
    pub fn as_str_name(&self) -> &'static str {
        match self {
            Self::Unspecified => "TRANSFER_STATE_UNSPECIFIED",
            Self::Pending => "PENDING",
            Self::Running => "RUNNING",
            Self::Succeeded => "SUCCEEDED",
            Self::Failed => "FAILED",
            Self::Cancelled => "CANCELLED",
        }
    }
    /// Creates an enum from field names used in the ProtoBuf definition.
    pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
        match value {
            "TRANSFER_STATE_UNSPECIFIED" => Some(Self::Unspecified),
            "PENDING" => Some(Self::Pending),
            "RUNNING" => Some(Self::Running),
            "SUCCEEDED" => Some(Self::Succeeded),
            "FAILED" => Some(Self::Failed),
            "CANCELLED" => Some(Self::Cancelled),
            _ => None,
        }
    }
}
/// A parameter used to define custom fields in a data source definition.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DataSourceParameter {
    /// Parameter identifier.
    #[prost(string, tag = "1")]
    pub param_id: ::prost::alloc::string::String,
    /// Parameter display name in the user interface.
    #[prost(string, tag = "2")]
    pub display_name: ::prost::alloc::string::String,
    /// Parameter description.
    #[prost(string, tag = "3")]
    pub description: ::prost::alloc::string::String,
    /// Parameter type.
    #[prost(enumeration = "data_source_parameter::Type", tag = "4")]
    pub r#type: i32,
    /// Is parameter required.
    #[prost(bool, tag = "5")]
    pub required: bool,
    /// Deprecated. This field has no effect.
    #[prost(bool, tag = "6")]
    pub repeated: bool,
    /// Regular expression which can be used for parameter validation.
    #[prost(string, tag = "7")]
    pub validation_regex: ::prost::alloc::string::String,
    /// All possible values for the parameter.
    #[prost(string, repeated, tag = "8")]
    pub allowed_values: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// For integer and double values specifies minimum allowed value.
    #[prost(message, optional, tag = "9")]
    pub min_value: ::core::option::Option<f64>,
    /// For integer and double values specifies maximum allowed value.
    #[prost(message, optional, tag = "10")]
    pub max_value: ::core::option::Option<f64>,
    /// Deprecated. This field has no effect.
    #[prost(message, repeated, tag = "11")]
    pub fields: ::prost::alloc::vec::Vec<DataSourceParameter>,
    /// Description of the requirements for this field, in case the user input does
    /// not fulfill the regex pattern or min/max values.
    #[prost(string, tag = "12")]
    pub validation_description: ::prost::alloc::string::String,
    /// URL to a help document to further explain the naming requirements.
    #[prost(string, tag = "13")]
    pub validation_help_url: ::prost::alloc::string::String,
    /// Cannot be changed after initial creation.
    #[prost(bool, tag = "14")]
    pub immutable: bool,
    /// Deprecated. This field has no effect.
    #[prost(bool, tag = "15")]
    pub recurse: bool,
    /// If true, it should not be used in new transfers, and it should not be
    /// visible to users.
    #[prost(bool, tag = "20")]
    pub deprecated: bool,
}
/// Nested message and enum types in `DataSourceParameter`.
pub mod data_source_parameter {
    /// Parameter type.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum Type {
        /// Type unspecified.
        Unspecified = 0,
        /// String parameter.
        String = 1,
        /// Integer parameter (64-bits).
        /// Will be serialized to json as string.
        Integer = 2,
        /// Double precision floating point parameter.
        Double = 3,
        /// Boolean parameter.
        Boolean = 4,
        /// Deprecated. This field has no effect.
        Record = 5,
        /// Page ID for a Google+ Page.
        PlusPage = 6,
        /// List of strings parameter.
        List = 7,
    }
    impl Type {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "TYPE_UNSPECIFIED",
                Self::String => "STRING",
                Self::Integer => "INTEGER",
                Self::Double => "DOUBLE",
                Self::Boolean => "BOOLEAN",
                Self::Record => "RECORD",
                Self::PlusPage => "PLUS_PAGE",
                Self::List => "LIST",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                "STRING" => Some(Self::String),
                "INTEGER" => Some(Self::Integer),
                "DOUBLE" => Some(Self::Double),
                "BOOLEAN" => Some(Self::Boolean),
                "RECORD" => Some(Self::Record),
                "PLUS_PAGE" => Some(Self::PlusPage),
                "LIST" => Some(Self::List),
                _ => None,
            }
        }
    }
}
/// Defines the properties and custom parameters for a data source.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DataSource {
    /// Output only. Data source resource name.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Data source id.
    #[prost(string, tag = "2")]
    pub data_source_id: ::prost::alloc::string::String,
    /// User friendly data source name.
    #[prost(string, tag = "3")]
    pub display_name: ::prost::alloc::string::String,
    /// User friendly data source description string.
    #[prost(string, tag = "4")]
    pub description: ::prost::alloc::string::String,
    /// Data source client id which should be used to receive refresh token.
    #[prost(string, tag = "5")]
    pub client_id: ::prost::alloc::string::String,
    /// Api auth scopes for which refresh token needs to be obtained. These are
    /// scopes needed by a data source to prepare data and ingest them into
    /// BigQuery, e.g., <https://www.googleapis.com/auth/bigquery>
    #[prost(string, repeated, tag = "6")]
    pub scopes: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Deprecated. This field has no effect.
    #[deprecated]
    #[prost(enumeration = "TransferType", tag = "7")]
    pub transfer_type: i32,
    /// Deprecated. This field has no effect.
    #[deprecated]
    #[prost(bool, tag = "8")]
    pub supports_multiple_transfers: bool,
    /// The number of seconds to wait for an update from the data source
    /// before the Data Transfer Service marks the transfer as FAILED.
    #[prost(int32, tag = "9")]
    pub update_deadline_seconds: i32,
    /// Default data transfer schedule.
    /// Examples of valid schedules include:
    /// `1st,3rd monday of month 15:30`,
    /// `every wed,fri of jan,jun 13:15`, and
    /// `first sunday of quarter 00:00`.
    #[prost(string, tag = "10")]
    pub default_schedule: ::prost::alloc::string::String,
    /// Specifies whether the data source supports a user defined schedule, or
    /// operates on the default schedule.
    /// When set to `true`, user can override default schedule.
    #[prost(bool, tag = "11")]
    pub supports_custom_schedule: bool,
    /// Data source parameters.
    #[prost(message, repeated, tag = "12")]
    pub parameters: ::prost::alloc::vec::Vec<DataSourceParameter>,
    /// Url for the help document for this data source.
    #[prost(string, tag = "13")]
    pub help_url: ::prost::alloc::string::String,
    /// Indicates the type of authorization.
    #[prost(enumeration = "data_source::AuthorizationType", tag = "14")]
    pub authorization_type: i32,
    /// Specifies whether the data source supports automatic data refresh for the
    /// past few days, and how it's supported.
    /// For some data sources, data might not be complete until a few days later,
    /// so it's useful to refresh data automatically.
    #[prost(enumeration = "data_source::DataRefreshType", tag = "15")]
    pub data_refresh_type: i32,
    /// Default data refresh window on days.
    /// Only meaningful when `data_refresh_type` = `SLIDING_WINDOW`.
    #[prost(int32, tag = "16")]
    pub default_data_refresh_window_days: i32,
    /// Disables backfilling and manual run scheduling
    /// for the data source.
    #[prost(bool, tag = "17")]
    pub manual_runs_disabled: bool,
    /// The minimum interval for scheduler to schedule runs.
    #[prost(message, optional, tag = "18")]
    pub minimum_schedule_interval: ::core::option::Option<::prost_types::Duration>,
}
/// Nested message and enum types in `DataSource`.
pub mod data_source {
    /// The type of authorization needed for this data source.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum AuthorizationType {
        /// Type unspecified.
        Unspecified = 0,
        /// Use OAuth 2 authorization codes that can be exchanged
        /// for a refresh token on the backend.
        AuthorizationCode = 1,
        /// Return an authorization code for a given Google+ page that can then be
        /// exchanged for a refresh token on the backend.
        GooglePlusAuthorizationCode = 2,
        /// Use First Party OAuth.
        FirstPartyOauth = 3,
    }
    impl AuthorizationType {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "AUTHORIZATION_TYPE_UNSPECIFIED",
                Self::AuthorizationCode => "AUTHORIZATION_CODE",
                Self::GooglePlusAuthorizationCode => "GOOGLE_PLUS_AUTHORIZATION_CODE",
                Self::FirstPartyOauth => "FIRST_PARTY_OAUTH",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "AUTHORIZATION_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                "AUTHORIZATION_CODE" => Some(Self::AuthorizationCode),
                "GOOGLE_PLUS_AUTHORIZATION_CODE" => {
                    Some(Self::GooglePlusAuthorizationCode)
                }
                "FIRST_PARTY_OAUTH" => Some(Self::FirstPartyOauth),
                _ => None,
            }
        }
    }
    /// Represents how the data source supports data auto refresh.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum DataRefreshType {
        /// The data source won't support data auto refresh, which is default value.
        Unspecified = 0,
        /// The data source supports data auto refresh, and runs will be scheduled
        /// for the past few days. Does not allow custom values to be set for each
        /// transfer config.
        SlidingWindow = 1,
        /// The data source supports data auto refresh, and runs will be scheduled
        /// for the past few days. Allows custom values to be set for each transfer
        /// config.
        CustomSlidingWindow = 2,
    }
    impl DataRefreshType {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "DATA_REFRESH_TYPE_UNSPECIFIED",
                Self::SlidingWindow => "SLIDING_WINDOW",
                Self::CustomSlidingWindow => "CUSTOM_SLIDING_WINDOW",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "DATA_REFRESH_TYPE_UNSPECIFIED" => Some(Self::Unspecified),
                "SLIDING_WINDOW" => Some(Self::SlidingWindow),
                "CUSTOM_SLIDING_WINDOW" => Some(Self::CustomSlidingWindow),
                _ => None,
            }
        }
    }
}
/// A request to get data source info.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetDataSourceRequest {
    /// Required. The field will contain name of the resource requested, for
    /// example: `projects/{project_id}/dataSources/{data_source_id}` or
    /// `projects/{project_id}/locations/{location_id}/dataSources/{data_source_id}`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
}
/// Request to list supported data sources and their data transfer settings.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListDataSourcesRequest {
    /// Required. The BigQuery project id for which data sources should be
    /// returned. Must be in the form: `projects/{project_id}` or
    /// `projects/{project_id}/locations/{location_id}`
    #[prost(string, tag = "1")]
    pub parent: ::prost::alloc::string::String,
    /// Pagination token, which can be used to request a specific page
    /// of `ListDataSourcesRequest` list results. For multiple-page
    /// results, `ListDataSourcesResponse` outputs
    /// a `next_page` token, which can be used as the
    /// `page_token` value to request the next page of list results.
    #[prost(string, tag = "3")]
    pub page_token: ::prost::alloc::string::String,
    /// Page size. The default page size is the maximum value of 1000 results.
    #[prost(int32, tag = "4")]
    pub page_size: i32,
}
/// Returns list of supported data sources and their metadata.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListDataSourcesResponse {
    /// List of supported data sources and their transfer settings.
    #[prost(message, repeated, tag = "1")]
    pub data_sources: ::prost::alloc::vec::Vec<DataSource>,
    /// Output only. The next-pagination token. For multiple-page list results,
    /// this token can be used as the
    /// `ListDataSourcesRequest.page_token`
    /// to request the next page of list results.
    #[prost(string, tag = "2")]
    pub next_page_token: ::prost::alloc::string::String,
}
/// A request to create a data transfer configuration. If new credentials are
/// needed for this transfer configuration, authorization info must be provided.
/// If authorization info is provided, the transfer configuration will be
/// associated with the user id corresponding to the authorization info.
/// Otherwise, the transfer configuration will be associated with the calling
/// user.
///
/// When using a cross project service account for creating a transfer config,
/// you must enable cross project service account usage. For more information,
/// see [Disable attachment of service accounts to resources in other
/// projects](<https://cloud.google.com/resource-manager/docs/organization-policy/restricting-service-accounts#disable_cross_project_service_accounts>).
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CreateTransferConfigRequest {
    /// Required. The BigQuery project id where the transfer configuration should
    /// be created. Must be in the format
    /// projects/{project_id}/locations/{location_id} or projects/{project_id}. If
    /// specified location and location of the destination bigquery dataset do not
    /// match - the request will fail.
    #[prost(string, tag = "1")]
    pub parent: ::prost::alloc::string::String,
    /// Required. Data transfer configuration to create.
    #[prost(message, optional, tag = "2")]
    pub transfer_config: ::core::option::Option<TransferConfig>,
    /// Deprecated: Authorization code was required when
    /// `transferConfig.dataSourceId` is 'youtube_channel' but it is no longer used
    /// in any data sources. Use `version_info` instead.
    ///
    /// Optional OAuth2 authorization code to use with this transfer configuration.
    /// This is required only if `transferConfig.dataSourceId` is 'youtube_channel'
    /// and new credentials are needed, as indicated by `CheckValidCreds`. In order
    /// to obtain authorization_code, make a request to the following URL:
    /// <pre class="prettyprint" suppresswarning="true">
    /// <https://bigquery.cloud.google.com/datatransfer/oauthz/auth?redirect_uri=urn:ietf:wg:oauth:2.0:oob&response_type=authorization_code&client_id=<var>client_id</var>&scope=<var>data_source_scopes</var>>
    /// </pre>
    /// * The <var>client_id</var> is the OAuth client_id of the data source as
    /// returned by ListDataSources method.
    /// * <var>data_source_scopes</var> are the scopes returned by ListDataSources
    /// method.
    ///
    /// Note that this should not be set when `service_account_name` is used to
    /// create the transfer config.
    #[deprecated]
    #[prost(string, tag = "3")]
    pub authorization_code: ::prost::alloc::string::String,
    /// Optional version info. This parameter replaces `authorization_code` which
    /// is no longer used in any data sources. This is required only if
    /// `transferConfig.dataSourceId` is 'youtube_channel' *or* new credentials
    /// are needed, as indicated by `CheckValidCreds`. In order to obtain version
    /// info, make a request to the following URL:
    /// <pre class="prettyprint" suppresswarning="true">
    /// <https://bigquery.cloud.google.com/datatransfer/oauthz/auth?redirect_uri=urn:ietf:wg:oauth:2.0:oob&response_type=version_info&client_id=<var>client_id</var>&scope=<var>data_source_scopes</var>>
    /// </pre>
    /// * The <var>client_id</var> is the OAuth client_id of the data source as
    /// returned by ListDataSources method.
    /// * <var>data_source_scopes</var> are the scopes returned by ListDataSources
    /// method.
    ///
    /// Note that this should not be set when `service_account_name` is used to
    /// create the transfer config.
    #[prost(string, tag = "5")]
    pub version_info: ::prost::alloc::string::String,
    /// Optional service account email. If this field is set, the transfer config
    /// will be created with this service account's credentials. It requires that
    /// the requesting user calling this API has permissions to act as this service
    /// account.
    ///
    /// Note that not all data sources support service account credentials when
    /// creating a transfer config. For the latest list of data sources, read about
    /// [using service
    /// accounts](<https://cloud.google.com/bigquery-transfer/docs/use-service-accounts>).
    #[prost(string, tag = "6")]
    pub service_account_name: ::prost::alloc::string::String,
}
/// A request to update a transfer configuration. To update the user id of the
/// transfer configuration, authorization info needs to be provided.
///
/// When using a cross project service account for updating a transfer config,
/// you must enable cross project service account usage. For more information,
/// see [Disable attachment of service accounts to resources in other
/// projects](<https://cloud.google.com/resource-manager/docs/organization-policy/restricting-service-accounts#disable_cross_project_service_accounts>).
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct UpdateTransferConfigRequest {
    /// Required. Data transfer configuration to create.
    #[prost(message, optional, tag = "1")]
    pub transfer_config: ::core::option::Option<TransferConfig>,
    /// Deprecated: Authorization code was required when
    /// `transferConfig.dataSourceId` is 'youtube_channel' but it is no longer used
    /// in any data sources. Use `version_info` instead.
    ///
    /// Optional OAuth2 authorization code to use with this transfer configuration.
    /// This is required only if `transferConfig.dataSourceId` is 'youtube_channel'
    /// and new credentials are needed, as indicated by `CheckValidCreds`. In order
    /// to obtain authorization_code, make a request to the following URL:
    /// <pre class="prettyprint" suppresswarning="true">
    /// <https://bigquery.cloud.google.com/datatransfer/oauthz/auth?redirect_uri=urn:ietf:wg:oauth:2.0:oob&response_type=authorization_code&client_id=<var>client_id</var>&scope=<var>data_source_scopes</var>>
    /// </pre>
    /// * The <var>client_id</var> is the OAuth client_id of the data source as
    /// returned by ListDataSources method.
    /// * <var>data_source_scopes</var> are the scopes returned by ListDataSources
    /// method.
    ///
    /// Note that this should not be set when `service_account_name` is used to
    /// update the transfer config.
    #[deprecated]
    #[prost(string, tag = "3")]
    pub authorization_code: ::prost::alloc::string::String,
    /// Required. Required list of fields to be updated in this request.
    #[prost(message, optional, tag = "4")]
    pub update_mask: ::core::option::Option<::prost_types::FieldMask>,
    /// Optional version info. This parameter replaces `authorization_code` which
    /// is no longer used in any data sources. This is required only if
    /// `transferConfig.dataSourceId` is 'youtube_channel' *or* new credentials
    /// are needed, as indicated by `CheckValidCreds`. In order to obtain version
    /// info, make a request to the following URL:
    /// <pre class="prettyprint" suppresswarning="true">
    /// <https://bigquery.cloud.google.com/datatransfer/oauthz/auth?redirect_uri=urn:ietf:wg:oauth:2.0:oob&response_type=version_info&client_id=<var>client_id</var>&scope=<var>data_source_scopes</var>>
    /// </pre>
    /// * The <var>client_id</var> is the OAuth client_id of the data source as
    /// returned by ListDataSources method.
    /// * <var>data_source_scopes</var> are the scopes returned by ListDataSources
    /// method.
    ///
    /// Note that this should not be set when `service_account_name` is used to
    /// update the transfer config.
    #[prost(string, tag = "5")]
    pub version_info: ::prost::alloc::string::String,
    /// Optional service account email. If this field is set, the transfer config
    /// will be created with this service account's credentials. It requires that
    /// the requesting user calling this API has permissions to act as this service
    /// account.
    ///
    /// Note that not all data sources support service account credentials when
    /// creating a transfer config. For the latest list of data sources, read about
    /// [using service
    /// accounts](<https://cloud.google.com/bigquery-transfer/docs/use-service-accounts>).
    #[prost(string, tag = "6")]
    pub service_account_name: ::prost::alloc::string::String,
}
/// A request to get data transfer information.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetTransferConfigRequest {
    /// Required. The field will contain name of the resource requested, for
    /// example: `projects/{project_id}/transferConfigs/{config_id}` or
    /// `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
}
/// A request to delete data transfer information. All associated transfer runs
/// and log messages will be deleted as well.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DeleteTransferConfigRequest {
    /// Required. The field will contain name of the resource requested, for
    /// example: `projects/{project_id}/transferConfigs/{config_id}` or
    /// `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
}
/// A request to get data transfer run information.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct GetTransferRunRequest {
    /// Required. The field will contain name of the resource requested, for
    /// example: `projects/{project_id}/transferConfigs/{config_id}/runs/{run_id}`
    /// or
    /// `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}/runs/{run_id}`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
}
/// A request to delete data transfer run information.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct DeleteTransferRunRequest {
    /// Required. The field will contain name of the resource requested, for
    /// example: `projects/{project_id}/transferConfigs/{config_id}/runs/{run_id}`
    /// or
    /// `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}/runs/{run_id}`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
}
/// A request to list data transfers configured for a BigQuery project.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListTransferConfigsRequest {
    /// Required. The BigQuery project id for which transfer configs
    /// should be returned: `projects/{project_id}` or
    /// `projects/{project_id}/locations/{location_id}`
    #[prost(string, tag = "1")]
    pub parent: ::prost::alloc::string::String,
    /// When specified, only configurations of requested data sources are returned.
    #[prost(string, repeated, tag = "2")]
    pub data_source_ids: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
    /// Pagination token, which can be used to request a specific page
    /// of `ListTransfersRequest` list results. For multiple-page
    /// results, `ListTransfersResponse` outputs
    /// a `next_page` token, which can be used as the
    /// `page_token` value to request the next page of list results.
    #[prost(string, tag = "3")]
    pub page_token: ::prost::alloc::string::String,
    /// Page size. The default page size is the maximum value of 1000 results.
    #[prost(int32, tag = "4")]
    pub page_size: i32,
}
/// The returned list of pipelines in the project.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListTransferConfigsResponse {
    /// Output only. The stored pipeline transfer configurations.
    #[prost(message, repeated, tag = "1")]
    pub transfer_configs: ::prost::alloc::vec::Vec<TransferConfig>,
    /// Output only. The next-pagination token. For multiple-page list results,
    /// this token can be used as the
    /// `ListTransferConfigsRequest.page_token`
    /// to request the next page of list results.
    #[prost(string, tag = "2")]
    pub next_page_token: ::prost::alloc::string::String,
}
/// A request to list data transfer runs.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListTransferRunsRequest {
    /// Required. Name of transfer configuration for which transfer runs should be
    /// retrieved. Format of transfer configuration resource name is:
    /// `projects/{project_id}/transferConfigs/{config_id}` or
    /// `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}`.
    #[prost(string, tag = "1")]
    pub parent: ::prost::alloc::string::String,
    /// When specified, only transfer runs with requested states are returned.
    #[prost(enumeration = "TransferState", repeated, tag = "2")]
    pub states: ::prost::alloc::vec::Vec<i32>,
    /// Pagination token, which can be used to request a specific page
    /// of `ListTransferRunsRequest` list results. For multiple-page
    /// results, `ListTransferRunsResponse` outputs
    /// a `next_page` token, which can be used as the
    /// `page_token` value to request the next page of list results.
    #[prost(string, tag = "3")]
    pub page_token: ::prost::alloc::string::String,
    /// Page size. The default page size is the maximum value of 1000 results.
    #[prost(int32, tag = "4")]
    pub page_size: i32,
    /// Indicates how run attempts are to be pulled.
    #[prost(enumeration = "list_transfer_runs_request::RunAttempt", tag = "5")]
    pub run_attempt: i32,
}
/// Nested message and enum types in `ListTransferRunsRequest`.
pub mod list_transfer_runs_request {
    /// Represents which runs should be pulled.
    #[derive(
        Clone,
        Copy,
        Debug,
        PartialEq,
        Eq,
        Hash,
        PartialOrd,
        Ord,
        ::prost::Enumeration
    )]
    #[repr(i32)]
    pub enum RunAttempt {
        /// All runs should be returned.
        Unspecified = 0,
        /// Only latest run per day should be returned.
        Latest = 1,
    }
    impl RunAttempt {
        /// String value of the enum field names used in the ProtoBuf definition.
        ///
        /// The values are not transformed in any way and thus are considered stable
        /// (if the ProtoBuf definition does not change) and safe for programmatic use.
        pub fn as_str_name(&self) -> &'static str {
            match self {
                Self::Unspecified => "RUN_ATTEMPT_UNSPECIFIED",
                Self::Latest => "LATEST",
            }
        }
        /// Creates an enum from field names used in the ProtoBuf definition.
        pub fn from_str_name(value: &str) -> ::core::option::Option<Self> {
            match value {
                "RUN_ATTEMPT_UNSPECIFIED" => Some(Self::Unspecified),
                "LATEST" => Some(Self::Latest),
                _ => None,
            }
        }
    }
}
/// The returned list of pipelines in the project.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListTransferRunsResponse {
    /// Output only. The stored pipeline transfer runs.
    #[prost(message, repeated, tag = "1")]
    pub transfer_runs: ::prost::alloc::vec::Vec<TransferRun>,
    /// Output only. The next-pagination token. For multiple-page list results,
    /// this token can be used as the
    /// `ListTransferRunsRequest.page_token`
    /// to request the next page of list results.
    #[prost(string, tag = "2")]
    pub next_page_token: ::prost::alloc::string::String,
}
/// A request to get user facing log messages associated with data transfer run.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListTransferLogsRequest {
    /// Required. Transfer run name in the form:
    /// `projects/{project_id}/transferConfigs/{config_id}/runs/{run_id}` or
    /// `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}/runs/{run_id}`
    #[prost(string, tag = "1")]
    pub parent: ::prost::alloc::string::String,
    /// Pagination token, which can be used to request a specific page
    /// of `ListTransferLogsRequest` list results. For multiple-page
    /// results, `ListTransferLogsResponse` outputs
    /// a `next_page` token, which can be used as the
    /// `page_token` value to request the next page of list results.
    #[prost(string, tag = "4")]
    pub page_token: ::prost::alloc::string::String,
    /// Page size. The default page size is the maximum value of 1000 results.
    #[prost(int32, tag = "5")]
    pub page_size: i32,
    /// Message types to return. If not populated - INFO, WARNING and ERROR
    /// messages are returned.
    #[prost(enumeration = "transfer_message::MessageSeverity", repeated, tag = "6")]
    pub message_types: ::prost::alloc::vec::Vec<i32>,
}
/// The returned list transfer run messages.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ListTransferLogsResponse {
    /// Output only. The stored pipeline transfer messages.
    #[prost(message, repeated, tag = "1")]
    pub transfer_messages: ::prost::alloc::vec::Vec<TransferMessage>,
    /// Output only. The next-pagination token. For multiple-page list results,
    /// this token can be used as the
    /// `GetTransferRunLogRequest.page_token`
    /// to request the next page of list results.
    #[prost(string, tag = "2")]
    pub next_page_token: ::prost::alloc::string::String,
}
/// A request to determine whether the user has valid credentials. This method
/// is used to limit the number of OAuth popups in the user interface. The
/// user id is inferred from the API call context.
/// If the data source has the Google+ authorization type, this method
/// returns false, as it cannot be determined whether the credentials are
/// already valid merely based on the user id.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct CheckValidCredsRequest {
    /// Required. The data source in the form:
    /// `projects/{project_id}/dataSources/{data_source_id}` or
    /// `projects/{project_id}/locations/{location_id}/dataSources/{data_source_id}`.
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
}
/// A response indicating whether the credentials exist and are valid.
#[derive(Clone, Copy, PartialEq, ::prost::Message)]
pub struct CheckValidCredsResponse {
    /// If set to `true`, the credentials exist and are valid.
    #[prost(bool, tag = "1")]
    pub has_valid_creds: bool,
}
/// A request to schedule transfer runs for a time range.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ScheduleTransferRunsRequest {
    /// Required. Transfer configuration name in the form:
    /// `projects/{project_id}/transferConfigs/{config_id}` or
    /// `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}`.
    #[prost(string, tag = "1")]
    pub parent: ::prost::alloc::string::String,
    /// Required. Start time of the range of transfer runs. For example,
    /// `"2017-05-25T00:00:00+00:00"`.
    #[prost(message, optional, tag = "2")]
    pub start_time: ::core::option::Option<::prost_types::Timestamp>,
    /// Required. End time of the range of transfer runs. For example,
    /// `"2017-05-30T00:00:00+00:00"`.
    #[prost(message, optional, tag = "3")]
    pub end_time: ::core::option::Option<::prost_types::Timestamp>,
}
/// A response to schedule transfer runs for a time range.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct ScheduleTransferRunsResponse {
    /// The transfer runs that were scheduled.
    #[prost(message, repeated, tag = "1")]
    pub runs: ::prost::alloc::vec::Vec<TransferRun>,
}
/// A request to start manual transfer runs.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StartManualTransferRunsRequest {
    /// Required. Transfer configuration name in the form:
    /// `projects/{project_id}/transferConfigs/{config_id}` or
    /// `projects/{project_id}/locations/{location_id}/transferConfigs/{config_id}`.
    #[prost(string, tag = "1")]
    pub parent: ::prost::alloc::string::String,
    /// The requested time specification - this can be a time range or a specific
    /// run_time.
    #[prost(oneof = "start_manual_transfer_runs_request::Time", tags = "3, 4")]
    pub time: ::core::option::Option<start_manual_transfer_runs_request::Time>,
}
/// Nested message and enum types in `StartManualTransferRunsRequest`.
pub mod start_manual_transfer_runs_request {
    /// A specification for a time range, this will request transfer runs with
    /// run_time between start_time (inclusive) and end_time (exclusive).
    #[derive(Clone, Copy, PartialEq, ::prost::Message)]
    pub struct TimeRange {
        /// Start time of the range of transfer runs. For example,
        /// `"2017-05-25T00:00:00+00:00"`. The start_time must be strictly less than
        /// the end_time. Creates transfer runs where run_time is in the range
        /// between start_time (inclusive) and end_time (exclusive).
        #[prost(message, optional, tag = "1")]
        pub start_time: ::core::option::Option<::prost_types::Timestamp>,
        /// End time of the range of transfer runs. For example,
        /// `"2017-05-30T00:00:00+00:00"`. The end_time must not be in the future.
        /// Creates transfer runs where run_time is in the range between start_time
        /// (inclusive) and end_time (exclusive).
        #[prost(message, optional, tag = "2")]
        pub end_time: ::core::option::Option<::prost_types::Timestamp>,
    }
    /// The requested time specification - this can be a time range or a specific
    /// run_time.
    #[derive(Clone, Copy, PartialEq, ::prost::Oneof)]
    pub enum Time {
        /// A time_range start and end timestamp for historical data files or reports
        /// that are scheduled to be transferred by the scheduled transfer run.
        /// requested_time_range must be a past time and cannot include future time
        /// values.
        #[prost(message, tag = "3")]
        RequestedTimeRange(TimeRange),
        /// A run_time timestamp for historical data files or reports
        /// that are scheduled to be transferred by the scheduled transfer run.
        /// requested_run_time must be a past time and cannot include future time
        /// values.
        #[prost(message, tag = "4")]
        RequestedRunTime(::prost_types::Timestamp),
    }
}
/// A response to start manual transfer runs.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct StartManualTransferRunsResponse {
    /// The transfer runs that were created.
    #[prost(message, repeated, tag = "1")]
    pub runs: ::prost::alloc::vec::Vec<TransferRun>,
}
/// A request to enroll a set of data sources so they are visible in the
/// BigQuery UI's `Transfer` tab.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct EnrollDataSourcesRequest {
    /// Required. The name of the project resource in the form:
    /// `projects/{project_id}`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Data sources that are enrolled. It is required to provide at least one
    /// data source id.
    #[prost(string, repeated, tag = "2")]
    pub data_source_ids: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// A request to unenroll a set of data sources so they are no longer visible in
/// the BigQuery UI's `Transfer` tab.
#[derive(Clone, PartialEq, ::prost::Message)]
pub struct UnenrollDataSourcesRequest {
    /// Required. The name of the project resource in the form:
    /// `projects/{project_id}`
    #[prost(string, tag = "1")]
    pub name: ::prost::alloc::string::String,
    /// Data sources that are unenrolled. It is required to provide at least one
    /// data source id.
    #[prost(string, repeated, tag = "2")]
    pub data_source_ids: ::prost::alloc::vec::Vec<::prost::alloc::string::String>,
}
/// Generated client implementations.
pub mod data_transfer_service_client {
    #![allow(
        unused_variables,
        dead_code,
        missing_docs,
        clippy::wildcard_imports,
        clippy::let_unit_value,
    )]
    use tonic::codegen::*;
    use tonic::codegen::http::Uri;
    /// This API allows users to manage their data transfers into BigQuery.
    #[derive(Debug, Clone)]
    pub struct DataTransferServiceClient<T> {
        inner: tonic::client::Grpc<T>,
    }
    impl DataTransferServiceClient<tonic::transport::Channel> {
        /// Attempt to create a new client by connecting to a given endpoint.
        pub async fn connect<D>(dst: D) -> Result<Self, tonic::transport::Error>
        where
            D: TryInto<tonic::transport::Endpoint>,
            D::Error: Into<StdError>,
        {
            let conn = tonic::transport::Endpoint::new(dst)?.connect().await?;
            Ok(Self::new(conn))
        }
    }
    impl<T> DataTransferServiceClient<T>
    where
        T: tonic::client::GrpcService<tonic::body::BoxBody>,
        T::Error: Into<StdError>,
        T::ResponseBody: Body<Data = Bytes> + std::marker::Send + 'static,
        <T::ResponseBody as Body>::Error: Into<StdError> + std::marker::Send,
    {
        pub fn new(inner: T) -> Self {
            let inner = tonic::client::Grpc::new(inner);
            Self { inner }
        }
        pub fn with_origin(inner: T, origin: Uri) -> Self {
            let inner = tonic::client::Grpc::with_origin(inner, origin);
            Self { inner }
        }
        pub fn with_interceptor<F>(
            inner: T,
            interceptor: F,
        ) -> DataTransferServiceClient<InterceptedService<T, F>>
        where
            F: tonic::service::Interceptor,
            T::ResponseBody: Default,
            T: tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
                Response = http::Response<
                    <T as tonic::client::GrpcService<tonic::body::BoxBody>>::ResponseBody,
                >,
            >,
            <T as tonic::codegen::Service<
                http::Request<tonic::body::BoxBody>,
            >>::Error: Into<StdError> + std::marker::Send + std::marker::Sync,
        {
            DataTransferServiceClient::new(InterceptedService::new(inner, interceptor))
        }
        /// Compress requests with the given encoding.
        ///
        /// This requires the server to support it otherwise it might respond with an
        /// error.
        #[must_use]
        pub fn send_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.send_compressed(encoding);
            self
        }
        /// Enable decompressing responses.
        #[must_use]
        pub fn accept_compressed(mut self, encoding: CompressionEncoding) -> Self {
            self.inner = self.inner.accept_compressed(encoding);
            self
        }
        /// Limits the maximum size of a decoded message.
        ///
        /// Default: `4MB`
        #[must_use]
        pub fn max_decoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_decoding_message_size(limit);
            self
        }
        /// Limits the maximum size of an encoded message.
        ///
        /// Default: `usize::MAX`
        #[must_use]
        pub fn max_encoding_message_size(mut self, limit: usize) -> Self {
            self.inner = self.inner.max_encoding_message_size(limit);
            self
        }
        /// Retrieves a supported data source and returns its settings.
        pub async fn get_data_source(
            &mut self,
            request: impl tonic::IntoRequest<super::GetDataSourceRequest>,
        ) -> std::result::Result<tonic::Response<super::DataSource>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/GetDataSource",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "GetDataSource",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Lists supported data sources and returns their settings.
        pub async fn list_data_sources(
            &mut self,
            request: impl tonic::IntoRequest<super::ListDataSourcesRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ListDataSourcesResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/ListDataSources",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "ListDataSources",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Creates a new data transfer configuration.
        pub async fn create_transfer_config(
            &mut self,
            request: impl tonic::IntoRequest<super::CreateTransferConfigRequest>,
        ) -> std::result::Result<tonic::Response<super::TransferConfig>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/CreateTransferConfig",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "CreateTransferConfig",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Updates a data transfer configuration.
        /// All fields must be set, even if they are not updated.
        pub async fn update_transfer_config(
            &mut self,
            request: impl tonic::IntoRequest<super::UpdateTransferConfigRequest>,
        ) -> std::result::Result<tonic::Response<super::TransferConfig>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/UpdateTransferConfig",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "UpdateTransferConfig",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Deletes a data transfer configuration, including any associated transfer
        /// runs and logs.
        pub async fn delete_transfer_config(
            &mut self,
            request: impl tonic::IntoRequest<super::DeleteTransferConfigRequest>,
        ) -> std::result::Result<tonic::Response<()>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/DeleteTransferConfig",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "DeleteTransferConfig",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Returns information about a data transfer config.
        pub async fn get_transfer_config(
            &mut self,
            request: impl tonic::IntoRequest<super::GetTransferConfigRequest>,
        ) -> std::result::Result<tonic::Response<super::TransferConfig>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/GetTransferConfig",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "GetTransferConfig",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Returns information about all transfer configs owned by a project in the
        /// specified location.
        pub async fn list_transfer_configs(
            &mut self,
            request: impl tonic::IntoRequest<super::ListTransferConfigsRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ListTransferConfigsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/ListTransferConfigs",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "ListTransferConfigs",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Creates transfer runs for a time range [start_time, end_time].
        /// For each date - or whatever granularity the data source supports - in the
        /// range, one transfer run is created.
        /// Note that runs are created per UTC time in the time range.
        /// DEPRECATED: use StartManualTransferRuns instead.
        #[deprecated]
        pub async fn schedule_transfer_runs(
            &mut self,
            request: impl tonic::IntoRequest<super::ScheduleTransferRunsRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ScheduleTransferRunsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/ScheduleTransferRuns",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "ScheduleTransferRuns",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Start manual transfer runs to be executed now with schedule_time equal to
        /// current time. The transfer runs can be created for a time range where the
        /// run_time is between start_time (inclusive) and end_time (exclusive), or for
        /// a specific run_time.
        pub async fn start_manual_transfer_runs(
            &mut self,
            request: impl tonic::IntoRequest<super::StartManualTransferRunsRequest>,
        ) -> std::result::Result<
            tonic::Response<super::StartManualTransferRunsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/StartManualTransferRuns",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "StartManualTransferRuns",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Returns information about the particular transfer run.
        pub async fn get_transfer_run(
            &mut self,
            request: impl tonic::IntoRequest<super::GetTransferRunRequest>,
        ) -> std::result::Result<tonic::Response<super::TransferRun>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/GetTransferRun",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "GetTransferRun",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Deletes the specified transfer run.
        pub async fn delete_transfer_run(
            &mut self,
            request: impl tonic::IntoRequest<super::DeleteTransferRunRequest>,
        ) -> std::result::Result<tonic::Response<()>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/DeleteTransferRun",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "DeleteTransferRun",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Returns information about running and completed transfer runs.
        pub async fn list_transfer_runs(
            &mut self,
            request: impl tonic::IntoRequest<super::ListTransferRunsRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ListTransferRunsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/ListTransferRuns",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "ListTransferRuns",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Returns log messages for the transfer run.
        pub async fn list_transfer_logs(
            &mut self,
            request: impl tonic::IntoRequest<super::ListTransferLogsRequest>,
        ) -> std::result::Result<
            tonic::Response<super::ListTransferLogsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/ListTransferLogs",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "ListTransferLogs",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Returns true if valid credentials exist for the given data source and
        /// requesting user.
        pub async fn check_valid_creds(
            &mut self,
            request: impl tonic::IntoRequest<super::CheckValidCredsRequest>,
        ) -> std::result::Result<
            tonic::Response<super::CheckValidCredsResponse>,
            tonic::Status,
        > {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/CheckValidCreds",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "CheckValidCreds",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Enroll data sources in a user project. This allows users to create transfer
        /// configurations for these data sources. They will also appear in the
        /// ListDataSources RPC and as such, will appear in the
        /// [BigQuery UI](https://console.cloud.google.com/bigquery), and the documents
        /// can be found in the public guide for
        /// [BigQuery Web UI](https://cloud.google.com/bigquery/bigquery-web-ui) and
        /// [Data Transfer
        /// Service](https://cloud.google.com/bigquery/docs/working-with-transfers).
        pub async fn enroll_data_sources(
            &mut self,
            request: impl tonic::IntoRequest<super::EnrollDataSourcesRequest>,
        ) -> std::result::Result<tonic::Response<()>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/EnrollDataSources",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "EnrollDataSources",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
        /// Unenroll data sources in a user project. This allows users to remove
        /// transfer configurations for these data sources. They will no longer appear
        /// in the ListDataSources RPC and will also no longer appear in the [BigQuery
        /// UI](https://console.cloud.google.com/bigquery). Data transfers
        /// configurations of unenrolled data sources will not be scheduled.
        pub async fn unenroll_data_sources(
            &mut self,
            request: impl tonic::IntoRequest<super::UnenrollDataSourcesRequest>,
        ) -> std::result::Result<tonic::Response<()>, tonic::Status> {
            self.inner
                .ready()
                .await
                .map_err(|e| {
                    tonic::Status::unknown(
                        format!("Service was not ready: {}", e.into()),
                    )
                })?;
            let codec = tonic::codec::ProstCodec::default();
            let path = http::uri::PathAndQuery::from_static(
                "/google.cloud.bigquery.datatransfer.v1.DataTransferService/UnenrollDataSources",
            );
            let mut req = request.into_request();
            req.extensions_mut()
                .insert(
                    GrpcMethod::new(
                        "google.cloud.bigquery.datatransfer.v1.DataTransferService",
                        "UnenrollDataSources",
                    ),
                );
            self.inner.unary(req, path, codec).await
        }
    }
}
